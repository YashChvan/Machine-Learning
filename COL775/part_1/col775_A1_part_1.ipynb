{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22990,
     "status": "ok",
     "timestamp": 1710165292524,
     "user": {
      "displayName": "yash chavan",
      "userId": "10144526596066718688"
     },
     "user_tz": -330
    },
    "id": "XgG0N3GWFzt5",
    "outputId": "79654e5a-4b44-4b93-eb49-3c0c2639813c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4578,
     "status": "ok",
     "timestamp": 1710165297099,
     "user": {
      "displayName": "yash chavan",
      "userId": "10144526596066718688"
     },
     "user_tz": -330
    },
    "id": "icmRCdmLp7iU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import dataloader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1710170413833,
     "user": {
      "displayName": "yash chavan",
      "userId": "10144526596066718688"
     },
     "user_tz": -330
    },
    "id": "mhOaSRtou7Rv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsampling = None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=\"same\",stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsamp = downsampling\n",
    "        self.stride = stride\n",
    "        self.topad = True\n",
    "        if self.downsamp is not None:\n",
    "            self.topad = False\n",
    "            self.stride = 1\n",
    "        \n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        out = x\n",
    "        # print(out.size())\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # print(out.size())\n",
    "        ih, iw = x.size()[-2:]\n",
    "        pad_h = self.calc_same_pad(i=ih, k=3, s=self.stride, d=1)\n",
    "        pad_w = self.calc_same_pad(i=iw, k=3, s=self.stride, d=1)\n",
    "        if (pad_h > 0 or pad_w > 0):\n",
    "            out= nn.functional.pad(\n",
    "                out, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "        # print(\"out size : \",out.size())\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsamp is not None:\n",
    "            identity = self.downsamp(x)\n",
    "        # print(out.size())\n",
    "        # print(\"out size after : \",out.size())\n",
    "        # print(\"identity size :\",identity.size())\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1710170417479,
     "user": {
      "displayName": "yash chavan",
      "userId": "10144526596066718688"
     },
     "user_tz": -330
    },
    "id": "udS6QxuRqL2z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class resnet(nn.Module):\n",
    "    def __init__(self,n,r):\n",
    "        super().__init__()\n",
    "        cluster1 = []\n",
    "        for i in range(n-1):\n",
    "            cluster1.append(block(16,16))\n",
    "        down1 = self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(16, 32, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(32)\n",
    "                )\n",
    "        cluster1.append(block(16,32,stride = 2,downsampling = down1))\n",
    "        self.c1 = nn.Sequential(*cluster1)\n",
    "\n",
    "        cluster2 = []\n",
    "        for i in range(n-1):\n",
    "            cluster2.append(block(32,32))\n",
    "        down2 = self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(64)\n",
    "                )\n",
    "        cluster2.append(block(32,64,stride = 2,downsampling = down2))\n",
    "        self.c2 = nn.Sequential(*cluster2)\n",
    "\n",
    "        cluster3 = []\n",
    "        for i in range(n):\n",
    "            cluster3.append(block(64,64))\n",
    "        self.c3 = nn.Sequential(*cluster3)\n",
    "        self.conv0 = nn.Conv2d(3,16,kernel_size=3,stride=1,padding=\"same\", bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.output = nn.Linear(64*32*32,r)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv0(x)\n",
    "        # print(out.size())\n",
    "        out = self.bn0(out)\n",
    "        # print(out.size())\n",
    "        out = self.relu(out)\n",
    "        # print(out.size())\n",
    "        out = self.c1(out)\n",
    "        out = self.c2(out)\n",
    "        out = self.c3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.reshape(-1,64*32*32)\n",
    "        # print(out.shape)\n",
    "        out = self.output(out)\n",
    "        # out = self.softmax(out)\n",
    "        # print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "onWb5xk8GaRM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.Resize(256)]\n",
    "#      )\n",
    "\n",
    "# batch_size = 32\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             432\n",
      "       BatchNorm2d-2         [-1, 16, 256, 256]              32\n",
      "              ReLU-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 16, 256, 256]           2,304\n",
      "       BatchNorm2d-5         [-1, 16, 256, 256]              32\n",
      "              ReLU-6         [-1, 16, 256, 256]               0\n",
      "            Conv2d-7         [-1, 16, 256, 256]           2,304\n",
      "       BatchNorm2d-8         [-1, 16, 256, 256]              32\n",
      "              ReLU-9         [-1, 16, 256, 256]               0\n",
      "            block-10         [-1, 16, 256, 256]               0\n",
      "           Conv2d-11         [-1, 32, 256, 256]           4,608\n",
      "      BatchNorm2d-12         [-1, 32, 256, 256]              64\n",
      "             ReLU-13         [-1, 32, 256, 256]               0\n",
      "           Conv2d-14         [-1, 32, 128, 128]           9,216\n",
      "      BatchNorm2d-15         [-1, 32, 128, 128]              64\n",
      "           Conv2d-16         [-1, 32, 128, 128]             512\n",
      "      BatchNorm2d-17         [-1, 32, 128, 128]              64\n",
      "             ReLU-18         [-1, 32, 128, 128]               0\n",
      "            block-19         [-1, 32, 128, 128]               0\n",
      "           Conv2d-20         [-1, 32, 128, 128]           9,216\n",
      "      BatchNorm2d-21         [-1, 32, 128, 128]              64\n",
      "             ReLU-22         [-1, 32, 128, 128]               0\n",
      "           Conv2d-23         [-1, 32, 128, 128]           9,216\n",
      "      BatchNorm2d-24         [-1, 32, 128, 128]              64\n",
      "             ReLU-25         [-1, 32, 128, 128]               0\n",
      "            block-26         [-1, 32, 128, 128]               0\n",
      "           Conv2d-27         [-1, 64, 128, 128]          18,432\n",
      "      BatchNorm2d-28         [-1, 64, 128, 128]             128\n",
      "             ReLU-29         [-1, 64, 128, 128]               0\n",
      "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
      "           Conv2d-32           [-1, 64, 64, 64]           2,048\n",
      "           Conv2d-33           [-1, 64, 64, 64]           2,048\n",
      "      BatchNorm2d-34           [-1, 64, 64, 64]             128\n",
      "      BatchNorm2d-35           [-1, 64, 64, 64]             128\n",
      "             ReLU-36           [-1, 64, 64, 64]               0\n",
      "            block-37           [-1, 64, 64, 64]               0\n",
      "           Conv2d-38           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-39           [-1, 64, 64, 64]             128\n",
      "             ReLU-40           [-1, 64, 64, 64]               0\n",
      "           Conv2d-41           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-42           [-1, 64, 64, 64]             128\n",
      "             ReLU-43           [-1, 64, 64, 64]               0\n",
      "            block-44           [-1, 64, 64, 64]               0\n",
      "           Conv2d-45           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-46           [-1, 64, 64, 64]             128\n",
      "             ReLU-47           [-1, 64, 64, 64]               0\n",
      "           Conv2d-48           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-49           [-1, 64, 64, 64]             128\n",
      "             ReLU-50           [-1, 64, 64, 64]               0\n",
      "            block-51           [-1, 64, 64, 64]               0\n",
      "        AvgPool2d-52           [-1, 64, 32, 32]               0\n",
      "           Linear-53                   [-1, 25]       1,638,425\n",
      "================================================================\n",
      "Total params: 1,884,521\n",
      "Trainable params: 1,884,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 248.50\n",
      "Params size (MB): 7.19\n",
      "Estimated Total Size (MB): 256.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "net = resnet(2,25)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "from torchsummary import summary\n",
    "summary(net,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         data\n",
    "#         inputs, labels = data\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         # print(labels)\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs)\n",
    "#         # outputs = torch.argmax(outputs,dim=1)\n",
    "#         # for i in range(outputs.shape[0]):\n",
    "#         #     outputs[i] = torch.argmax(outputs[i])\n",
    "#         # print(outputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 10 == 9:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         # calculate outputs by running images through the network\n",
    "#         outputs = net(images)\n",
    "#         # the class with the highest energy is what we choose as prediction\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asian-Green-Bee-Eater', 'Brown-Headed-Barbet', 'Cattle-Egret', 'Common-Kingfisher', 'Common-Myna', 'Common-Rosefinch', 'Common-Tailorbird', 'Coppersmith-Barbet', 'Forest-Wagtail', 'Gray-Wagtail', 'Hoopoe', 'House-Crow', 'Indian-Grey-Hornbill', 'Indian-Peacock', 'Indian-Pitta', 'Indian-Roller', 'Jungle-Babbler', 'Northern-Lapwing', 'Red-Wattled-Lapwing', 'Ruddy-Shelduck', 'Rufous-Treepie', 'Sarus-Crane', 'White-Breasted-Kingfisher', 'White-Breasted-Waterhen', 'White-Wagtail']\n"
     ]
    }
   ],
   "source": [
    "classes = ['Asian-Green-Bee-Eater','Brown-Headed-Barbet','Cattle-Egret','Common-Kingfisher', 'Common-Myna', 'Common-Rosefinch', 'Common-Tailorbird', 'Coppersmith-Barbet', 'Forest-Wagtail', 'Gray-Wagtail', 'Hoopoe', 'House-Crow', 'Indian-Grey-Hornbill', 'Indian-Peacock', 'Indian-Pitta', 'Indian-Roller', 'Jungle-Babbler', 'Northern-Lapwing', 'Red-Wattled-Lapwing', 'Ruddy-Shelduck', 'Rufous-Treepie', 'Sarus-Crane', 'White-Breasted-Kingfisher', 'White-Breasted-Waterhen', 'White-Wagtail']\n",
    "classes = sorted(classes)\n",
    "nametonum = {}\n",
    "numtoname = {}\n",
    "for i in range(25):\n",
    "    nametonum[classes[i]] = i\n",
    "    numtoname[i] = classes[i]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_targets = []\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "for i in range(25):\n",
    "    folder = \"E:/col775/Birds_25/train/\"+classes[i]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            train_dataset.append(img)\n",
    "            train_targets.append(i)\n",
    "print(\"done\")\n",
    "train_dataset = torch.Tensor(train_dataset).to(device)\n",
    "train_targets = torch.Tensor(train_targets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "val_targets = []\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "for i in range(25):\n",
    "    folder = \"E:/col775/Birds_25/val/\"+classes[i]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            val_dataset.append(img)\n",
    "            val_targets.append(i)\n",
    "val_dataset = torch.Tensor(val_dataset)\n",
    "val_targets = torch.Tensor(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "test_targets = []\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "for i in range(25):\n",
    "    folder = \"E:/col775/Birds_25/test/\"+classes[i]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            test_dataset.append(img)\n",
    "            test_targets.append(i)\n",
    "test_dataset = torch.Tensor(test_dataset)\n",
    "test_targets = torch.Tensor(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision import transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, data, targets, transform=None):\n",
    "#         self.data = data\n",
    "#         self.targets = torch.LongTensor(targets)\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         x = self.data[index]\n",
    "#         y = self.targets[index]\n",
    "        \n",
    "#         if self.transform:\n",
    "#             x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1,2,0))\n",
    "#             x = self.transform(x)\n",
    "        \n",
    "#         return x, y\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# def shuffler (arr, n):\n",
    "     \n",
    "#     # We will Start from the last element \n",
    "#     # and swap one by one.\n",
    "#     for i in range(n-1,0,-1):\n",
    "         \n",
    "#         # Pick a random index from 0 to i\n",
    "#         j = random.randint(0,i+1)\n",
    "         \n",
    "#         # Swap arr[i] with the element at random index\n",
    "#         arr[i],arr[j] = arr[j],arr[i]\n",
    "#     return arr\n",
    "# def make_mini_batch(data,targets,batch_size):\n",
    "#     # print(data.shape)\n",
    "#     num_batches = int(len(targets)/batch_size)\n",
    "#     aug = []\n",
    "#     new_data = [[] for i in range(len(targets))]\n",
    "#     new_targets = [-1 for i in range(len(targets))]\n",
    "#     for i in range(len(targets)):\n",
    "#         aug.append(i)\n",
    "#     aug = shuffler(aug,len(targets))\n",
    "#     print(aug[0])\n",
    "#     # for i in range(len(targets)):\n",
    "#     #     new_data[i] = aug[i][0]\n",
    "#     #     new_targets[i] = aug[i][1]\n",
    "#     batch_data = [[] for i in range(num_batches)]\n",
    "#     batch_targets = [[] for i in range(num_batches)]\n",
    "#     for i in range(len(targets)):\n",
    "#         batch_data[int(i/len(targets))].append(data[aug[i]])\n",
    "#         batch_targets[int(i/len(targets))].append(targets[aug[i]])\n",
    "#     batch= [[] for i in range(num_batches)]\n",
    "#     for i in range(num_batches):\n",
    "#         batch[int(i)].append([torch.Tensor(batch_data[i]),torch.Tensor(batch_targets[i])])\n",
    "#     return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.Resize(256)]\n",
    "#      )\n",
    "\n",
    "# batch_size = 8\n",
    "# train_set = MyDataset(train_dataset,train_targets,transforms)\n",
    "# val_set = MyDataset(val_dataset,val_targets,transforms)\n",
    "# test_set = MyDataset(test_dataset,test_targets,transforms)\n",
    "# # trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "# trainloader = make_mini_batch(train_dataset,train_targets,32)\n",
    "# # valloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "# # testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = {}\n",
    "prev_val_loss = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0], data[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = 100 # or whatever\n",
    "# batch_size = 128 # or whatever\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "\n",
    "#     # X is a torch Variable\n",
    "#     permutation = torch.randperm(X.size()[0])\n",
    "\n",
    "#     for i in range(0,X.size()[0], batch_size):\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         indices = permutation[i:i+batch_size]\n",
    "#         batch_x, batch_y = X[indices], Y[indices]\n",
    "\n",
    "#         # in case you wanted a semi-full example\n",
    "#         outputs = model(batch_x)\n",
    "#         loss = lossfunction(outputs,batch_y)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 100 # or whatever\n",
    "batch_size = 32 # or whatever\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    permutation = torch.randperm(train_targets.size()[0])\n",
    "    for i in range(0,X.size()[0], batch_size):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = train_data[i:i+batch_size],train_targets[i:i+batch_size]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    running_loss/=len(trainloder)\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(valloader)\n",
    "    losses[epoch] = [running_loss,val_loss]\n",
    "    if(val_loss < prev_val_loss):\n",
    "        prev_val_loss = val_loss\n",
    "        torch.save(net.state_dict(), r\"E:\\col775\\model_saves\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOXkuPWL4xMfK+CQNgugzC+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "pyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
